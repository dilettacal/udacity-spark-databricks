{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e0181e0-54a3-46a1-9ca1-c8ec9690cb48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data provisioning\n",
    "\n",
    "Data is uploaded manually to the file store. \n",
    "The paths are:\n",
    "- stations.csv = /FileStore/tables/stations.csv\n",
    "- riders.csv = /FileStore/tables/riders.csv\n",
    "- payments.csv = /FileStore/tables/payments.csv\n",
    "- trips.csv = /FileStore/tables/trips.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "073a9ea4-bdf4-44e3-a6ba-d591a6b41875",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create bronze schema\n",
    "Create bronze schemas for raw data ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f9913a-3cd9-4b8b-af7d-e907a4a32590",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS silver\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d503d10-d95f-4117-9f7a-ea9d11d872e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Read files\n",
    "Files were manually uploaded to FileStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e6d1eb-20b3-49f9-bff0-c7367b7bb706",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stations_df = (spark.read.option(\"header\", False).option(\"inferSchema\", True)\n",
    "               .csv(\"/FileStore/tables/stations.csv\"))\n",
    "riders_df   = (spark.read.option(\"header\", False).option(\"inferSchema\", True)\n",
    "               .csv(\"/FileStore/tables/riders.csv\"))\n",
    "payments_df = (spark.read.option(\"header\", False).option(\"inferSchema\", True)\n",
    "               .csv(\"/FileStore/tables/payments.csv\"))\n",
    "trips_df    = (spark.read.option(\"header\", False).option(\"inferSchema\", True)\n",
    "               .csv(\"/FileStore/tables/trips.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "892f4409-40df-4038-90f1-c843a18674d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(stations_df)\n",
    "display(riders_df)\n",
    "display(payments_df)\n",
    "display(trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a7d69d6-d714-4b0a-9088-2372c4cb44b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stations_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.stations\")\n",
    "riders_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.riders\")\n",
    "payments_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.payments\")\n",
    "trips_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9ee9ede-1f6a-46cc-afa8-1609ecb91ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS count_stations FROM bronze.stations\").show()\n",
    "spark.sql(\"SELECT COUNT(*) AS count_riders FROM bronze.riders\").show()\n",
    "spark.sql(\"SELECT COUNT(*) AS count_payments FROM bronze.payments\").show()\n",
    "spark.sql(\"SELECT COUNT(*) AS count_trips FROM bronze.trips\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da593fb4-4055-4de6-b89e-2009ecb64151",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Stage\n",
    "In this stage, raw Bronze tables were standardized into clean Silver tables for analytics-ready transformations.\n",
    "\n",
    "## Transformations\n",
    "1. Renamed generic columns (_c0, _c1, â€¦) to business column names based on the dataset schema.\n",
    "2. Applied relevant type casting\n",
    "3. Derived trip metrics, e.g. `trip_duration_minutes` from `ended_at` and `started_at`\n",
    "4. Applied basic quality filters, e.g. removed rows with null required keys\n",
    "\n",
    "## Outputs\n",
    "Cleaned outputs were witten to:\n",
    "`silver.stations`\n",
    "`silver.riders`\n",
    "`silver.payments`\n",
    "`silver.trips`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49933f72-6894-4e7c-bf99-64ea2cc2076f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Ensure schema exists \n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS silver\")\n",
    "\n",
    "# -------------------------\n",
    "# stations\n",
    "# -------------------------\n",
    "stations_silver = (\n",
    "    spark.table(\"bronze.stations\")\n",
    "    .select(\n",
    "        F.col(\"_c0\").cast(\"string\").alias(\"station_id\"),\n",
    "        F.col(\"_c1\").cast(\"string\").alias(\"name\"),\n",
    "        F.col(\"_c2\").cast(\"double\").alias(\"latitude\"),\n",
    "        F.col(\"_c3\").cast(\"double\").alias(\"longitude\")\n",
    "    )\n",
    "    .filter(F.col(\"station_id\").isNotNull())\n",
    ")\n",
    "\n",
    "# write\n",
    "stations_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.stations\")\n",
    "\n",
    "# -------------------------\n",
    "# riders\n",
    "# -------------------------\n",
    "riders_silver = (\n",
    "    spark.table(\"bronze.riders\")\n",
    "    .select(\n",
    "        F.col(\"_c0\").cast(\"int\").alias(\"rider_id\"),\n",
    "        F.col(\"_c1\").cast(\"string\").alias(\"first\"),\n",
    "        F.col(\"_c2\").cast(\"string\").alias(\"last\"),\n",
    "        F.col(\"_c3\").cast(\"string\").alias(\"address\"),\n",
    "        F.to_date(F.col(\"_c4\")).alias(\"birthday\"),\n",
    "        F.to_date(F.col(\"_c5\")).alias(\"account_start_date\"),\n",
    "        F.to_date(F.col(\"_c6\")).alias(\"account_end_date\"),\n",
    "        F.col(\"_c7\").cast(\"boolean\").alias(\"is_member\")\n",
    "    )\n",
    "    .filter(F.col(\"rider_id\").isNotNull())\n",
    ")\n",
    "\n",
    "# write \n",
    "riders_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.riders\")\n",
    "\n",
    "# -------------------------\n",
    "# payments\n",
    "# -------------------------\n",
    "payments_silver = (\n",
    "    spark.table(\"bronze.payments\")\n",
    "    .select(\n",
    "        F.col(\"_c0\").cast(\"int\").alias(\"payment_id\"),\n",
    "        F.to_date(F.col(\"_c1\")).alias(\"payment_date\"),\n",
    "        F.col(\"_c2\").cast(\"decimal(10,2)\").alias(\"amount\"),\n",
    "        F.col(\"_c3\").cast(\"int\").alias(\"rider_id\")\n",
    "    )\n",
    "    .filter(F.col(\"payment_id\").isNotNull() & F.col(\"rider_id\").isNotNull())\n",
    ")\n",
    "\n",
    "# write\n",
    "payments_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.payments\")\n",
    "\n",
    "# -------------------------\n",
    "# trips\n",
    "# -------------------------\n",
    "trips_silver = (\n",
    "    spark.table(\"bronze.trips\")\n",
    "    .select(\n",
    "        F.col(\"_c0\").cast(\"string\").alias(\"trip_id\"),\n",
    "        F.col(\"_c1\").cast(\"string\").alias(\"rideable_type\"),\n",
    "        F.to_timestamp(F.col(\"_c2\")).alias(\"started_at\"),\n",
    "        F.to_timestamp(F.col(\"_c3\")).alias(\"ended_at\"),\n",
    "        F.col(\"_c4\").cast(\"string\").alias(\"start_station_id\"),\n",
    "        F.col(\"_c5\").cast(\"string\").alias(\"end_station_id\"),\n",
    "        F.col(\"_c6\").cast(\"int\").alias(\"rider_id\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"trip_duration_minutes\",\n",
    "        (F.col(\"ended_at\").cast(\"long\") - F.col(\"started_at\").cast(\"long\")) / F.lit(60.0)\n",
    "    )\n",
    "    .filter(\n",
    "        F.col(\"trip_id\").isNotNull() &\n",
    "        F.col(\"started_at\").isNotNull() &\n",
    "        F.col(\"ended_at\").isNotNull() &\n",
    "        F.col(\"rider_id\").isNotNull()\n",
    "    )\n",
    ")\n",
    "\n",
    "# write \n",
    "trips_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.trips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71c19bcd-45d8-4846-9391-eae2d84c03fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Checks \n",
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"silver.stations\", spark.table(\"silver.stations\").count()),\n",
    "        (\"silver.riders\",   spark.table(\"silver.riders\").count()),\n",
    "        (\"silver.payments\", spark.table(\"silver.payments\").count()),\n",
    "        (\"silver.trips\",    spark.table(\"silver.trips\").count())\n",
    "    ], [\"table_name\", \"row_count\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a35af3e2-1267-4d94-a53d-d1008bf41e38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold Stage\n",
    "Data is prepared for analytics.\n",
    "\n",
    "- Dimension tables\n",
    "  - gold.dim_rider\n",
    "  - gold.dim_station\n",
    "  - gold.dim_date\n",
    "\n",
    "- Fact tables\n",
    "  - gold.fact_trip\n",
    "  - gold.fact_payment\n",
    "\n",
    "### Transformations\n",
    "1. Built shared dimensions for riders, stations and dates.\n",
    "2. Created `fact_trips` with `trip_duration_minutes`, `rider_age_at_trip`, where each row represents a trip\n",
    "3. Created `fact_payments` with `payment_amount`\n",
    "\n",
    "### Output\n",
    "The tables were saved as delta tables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc495ee-f747-44ef-bc8f-2efb41878fd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create schema if not already existing\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb7d77ea-5e83-45f7-953a-21755fa44a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build dimensions\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#### Riders \n",
    "dim_rider = (\n",
    "    spark.table(\"silver.riders\")\n",
    "    .select(\n",
    "        F.col(\"rider_id\"),\n",
    "        F.col(\"first\"),\n",
    "        F.col(\"last\"),\n",
    "        F.col(\"birthday\"),\n",
    "        F.col(\"account_start_date\"),\n",
    "        F.col(\"account_end_date\"),\n",
    "        F.col(\"is_member\")\n",
    "    )\n",
    "    .dropDuplicates([\"rider_id\"])\n",
    ")\n",
    "\n",
    "dim_rider.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.dim_rider\")\n",
    "\n",
    "### Stations\n",
    "dim_station = (\n",
    "    spark.table(\"silver.stations\")\n",
    "    .select(\"station_id\", \"name\", \"latitude\", \"longitude\")\n",
    "    .dropDuplicates([\"station_id\"])\n",
    ")\n",
    "\n",
    "# write \n",
    "dim_station.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.dim_station\")\n",
    "\n",
    "### Trips \n",
    "trip_dates = (\n",
    "    spark.table(\"silver.trips\")\n",
    "    .select(F.to_date(\"started_at\").alias(\"date\"))\n",
    "    .union(spark.table(\"silver.trips\").select(F.to_date(\"ended_at\").alias(\"date\")))\n",
    ")\n",
    "\n",
    "payment_dates = spark.table(\"silver.payments\").select(F.col(\"payment_date\").alias(\"date\"))\n",
    "\n",
    "all_dates = trip_dates.union(payment_dates).filter(F.col(\"date\").isNotNull()).dropDuplicates()\n",
    "\n",
    "\n",
    "### Dates \n",
    "dim_date = (\n",
    "    all_dates\n",
    "    .withColumn(\"date_key\", F.date_format(\"date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"year\", F.year(\"date\"))\n",
    "    .withColumn(\"quarter\", F.quarter(\"date\"))\n",
    "    .withColumn(\"month\", F.month(\"date\"))\n",
    "    .withColumn(\"day\", F.dayofmonth(\"date\"))\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"date\"))\n",
    "    .select(\"date_key\", \"date\", \"year\", \"quarter\", \"month\", \"day\", \"day_of_week\")\n",
    ")\n",
    "\n",
    "# write\n",
    "dim_date.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.dim_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2ada43c-01cc-463b-9f32-75a49b5a588f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build fact tables with trip_duration_minutes and rider_age_at_trip\n",
    "trips = spark.table(\"silver.trips\")\n",
    "riders = spark.table(\"gold.dim_rider\")\n",
    "\n",
    "fact_trip = (\n",
    "    trips.alias(\"t\")\n",
    "    .join(riders.alias(\"r\"), F.col(\"t.rider_id\") == F.col(\"r.rider_id\"), \"left\")\n",
    "    .withColumn(\"start_date\", F.to_date(\"t.started_at\"))\n",
    "    .withColumn(\"end_date\", F.to_date(\"t.ended_at\"))\n",
    "    .withColumn(\"start_date_key\", F.date_format(\"start_date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"end_date_key\", F.date_format(\"end_date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\n",
    "        \"rider_age_at_trip\",\n",
    "        F.floor(F.months_between(F.col(\"t.started_at\"), F.col(\"r.birthday\")) / 12)\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"t.trip_id\"),\n",
    "        F.col(\"t.rider_id\"),\n",
    "        F.col(\"t.start_station_id\"),\n",
    "        F.col(\"t.end_station_id\"),\n",
    "        F.col(\"start_date_key\"),\n",
    "        F.col(\"end_date_key\"),\n",
    "        F.col(\"t.rideable_type\"),\n",
    "        F.col(\"t.trip_duration_minutes\"),\n",
    "        F.col(\"rider_age_at_trip\")\n",
    "    )\n",
    ")\n",
    "\n",
    "fact_trip.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.fact_trip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf580c73-b313-4b9a-a700-f4a3b297bdb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# fact_payment (includes required payment amount)\n",
    "\n",
    "payments = spark.table(\"silver.payments\")\n",
    "\n",
    "fact_payment = (\n",
    "    payments\n",
    "    .withColumn(\"payment_date_key\", F.date_format(\"payment_date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "    .select(\n",
    "        \"payment_id\",\n",
    "        \"rider_id\",\n",
    "        \"payment_date_key\",\n",
    "        F.col(\"amount\").alias(\"payment_amount\")\n",
    "    )\n",
    ")\n",
    "\n",
    "fact_payment.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.fact_payment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6dd6e72-2ca4-44bb-bac7-973c6f15176e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check \n",
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"gold.dim_rider\",   spark.table(\"gold.dim_rider\").count()),\n",
    "        (\"gold.dim_station\", spark.table(\"gold.dim_station\").count()),\n",
    "        (\"gold.dim_date\",    spark.table(\"gold.dim_date\").count()),\n",
    "        (\"gold.fact_trip\",   spark.table(\"gold.fact_trip\").count()),\n",
    "        (\"gold.fact_payment\",spark.table(\"gold.fact_payment\").count())\n",
    "    ], [\"table_name\", \"row_count\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21dd1a9f-7256-43d2-adf0-34d455578c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Business Cases\n",
    "In this stage, the Gold star schema is used to answer the required business questions through aggregations and joins.\n",
    "\n",
    "Analyses \n",
    "1. Ride time analysis\n",
    "- Average and total trip duration by date dimensions (day/month/year, day of week).\n",
    "- Trip duration by station context (start station and end station).\n",
    "- Trip duration by rider context (age at trip and member/casual status).\n",
    "\n",
    "2. Payment analysis\n",
    "- Total and average payment amount by month, quarter, and year.\n",
    "- Payment totals per rider, including age at account start.\n",
    "\n",
    "3. (Optional extra credit)\n",
    "\n",
    "- Monthly spend per member analyzed alongside:\n",
    "  - average rides per month\n",
    "  - total minutes ridden per month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "522ccee0-56f7-4879-9458-1b3381d62ff5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Analyse time spent per ride\n",
    "## By day of week and month\n",
    "\n",
    "fact_trip = spark.table(\"gold.fact_trip\")\n",
    "dim_date  = spark.table(\"gold.dim_date\")\n",
    "\n",
    "q1a = (\n",
    "    fact_trip.alias(\"ft\")\n",
    "    .join(dim_date.alias(\"d\"), F.col(\"ft.start_date_key\") == F.col(\"d.date_key\"), \"left\")\n",
    "    .groupBy(\"d.year\", \"d.month\", \"d.day_of_week\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"ride_count\"),\n",
    "        F.round(F.avg(\"ft.trip_duration_minutes\"), 2).alias(\"avg_trip_minutes\"),\n",
    "        F.round(F.sum(\"ft.trip_duration_minutes\"), 2).alias(\"total_trip_minutes\")\n",
    "    )\n",
    "    .orderBy(\"d.year\", \"d.month\", \"d.day_of_week\")\n",
    ")\n",
    "\n",
    "display(q1a)\n",
    "\n",
    "## By time of day (hour)\n",
    "silver_trips = spark.table(\"silver.trips\")\n",
    "\n",
    "q1b = (\n",
    "    silver_trips\n",
    "    .withColumn(\"hour_of_day\", F.hour(\"started_at\"))\n",
    "    .groupBy(\"hour_of_day\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"ride_count\"),\n",
    "        F.round(F.avg(\"trip_duration_minutes\"), 2).alias(\"avg_trip_minutes\")\n",
    "    )\n",
    "    .orderBy(\"hour_of_day\")\n",
    ")\n",
    "\n",
    "display(q1b)\n",
    "\n",
    "## By start and end station\n",
    "dim_station = spark.table(\"gold.dim_station\")\n",
    "\n",
    "q1c = (\n",
    "    fact_trip.alias(\"ft\")\n",
    "    .join(dim_station.alias(\"ss\"), F.col(\"ft.start_station_id\") == F.col(\"ss.station_id\"), \"left\")\n",
    "    .join(dim_station.alias(\"es\"), F.col(\"ft.end_station_id\") == F.col(\"es.station_id\"), \"left\")\n",
    "    .groupBy(\n",
    "        F.col(\"ss.name\").alias(\"start_station\"),\n",
    "        F.col(\"es.name\").alias(\"end_station\")\n",
    "    )\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"ride_count\"),\n",
    "        F.round(F.avg(\"ft.trip_duration_minutes\"), 2).alias(\"avg_trip_minutes\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"ride_count\"))\n",
    ")\n",
    "\n",
    "display(q1c)\n",
    "\n",
    "## By rider age at trip + member/casual\n",
    "dim_rider = spark.table(\"gold.dim_rider\")\n",
    "\n",
    "q1d = (\n",
    "    fact_trip.alias(\"ft\")\n",
    "    .join(dim_rider.alias(\"r\"), \"rider_id\", \"left\")\n",
    "    .withColumn(\n",
    "        \"member_type\",\n",
    "        F.when(F.col(\"r.is_member\") == True, F.lit(\"member\")).otherwise(F.lit(\"casual\"))\n",
    "    )\n",
    "    .groupBy(\"member_type\", \"ft.rider_age_at_trip\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"ride_count\"),\n",
    "        F.round(F.avg(\"ft.trip_duration_minutes\"), 2).alias(\"avg_trip_minutes\")\n",
    "    )\n",
    "    .orderBy(\"member_type\", \"ft.rider_age_at_trip\")\n",
    ")\n",
    "\n",
    "display(q1d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2617d478-a46e-460e-a1b8-bbd5e869dd11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Analyze how much money is spent\n",
    "## Per month / quarter / year\n",
    "\n",
    "fact_payment = spark.table(\"gold.fact_payment\")\n",
    "\n",
    "q2a = (\n",
    "    fact_payment.alias(\"fp\")\n",
    "    .join(dim_date.alias(\"d\"), F.col(\"fp.payment_date_key\") == F.col(\"d.date_key\"), \"left\")\n",
    "    .groupBy(\"d.year\", \"d.quarter\", \"d.month\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"payment_count\"),\n",
    "        F.round(F.sum(\"fp.payment_amount\"), 2).alias(\"total_amount\"),\n",
    "        F.round(F.avg(\"fp.payment_amount\"), 2).alias(\"avg_payment_amount\")\n",
    "    )\n",
    "    .orderBy(\"d.year\", \"d.quarter\", \"d.month\")\n",
    ")\n",
    "\n",
    "display(q2a)\n",
    "\n",
    "## Per member, based on age at account start\n",
    "q2b = (\n",
    "    fact_payment.alias(\"fp\")\n",
    "    .join(dim_rider.alias(\"r\"), \"rider_id\", \"left\")\n",
    "    .withColumn(\n",
    "        \"age_at_account_start\",\n",
    "        F.floor(F.months_between(F.col(\"r.account_start_date\"), F.col(\"r.birthday\")) / 12)\n",
    "    )\n",
    "    .groupBy(\"fp.rider_id\", \"age_at_account_start\")\n",
    "    .agg(\n",
    "        F.round(F.sum(\"fp.payment_amount\"), 2).alias(\"total_amount\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"total_amount\"))\n",
    ")\n",
    "\n",
    "display(q2b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd882ea9-68ee-44ab-9f27-1584bf76d1d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Extra credit: spend per member by monthly ride behavior\n",
    "## Build monthly rides + minutes per rider\n",
    "rides_monthly = (\n",
    "    fact_trip.alias(\"ft\")\n",
    "    .join(dim_date.alias(\"d\"), F.col(\"ft.start_date_key\") == F.col(\"d.date_key\"), \"left\")\n",
    "    .groupBy(\"ft.rider_id\", \"d.year\", \"d.month\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"rides_per_month\"),\n",
    "        F.round(F.sum(\"ft.trip_duration_minutes\"), 2).alias(\"minutes_per_month\")\n",
    "    )\n",
    ")\n",
    "\n",
    "## Build monthly spend per rider\n",
    "payments_monthly = (\n",
    "    fact_payment.alias(\"fp\")\n",
    "    .join(dim_date.alias(\"d\"), F.col(\"fp.payment_date_key\") == F.col(\"d.date_key\"), \"left\")\n",
    "    .groupBy(\"fp.rider_id\", \"d.year\", \"d.month\")\n",
    "    .agg(\n",
    "        F.round(F.sum(\"fp.payment_amount\"), 2).alias(\"spend_per_month\")\n",
    "    )\n",
    ")\n",
    "\n",
    "## Combine and analyze\n",
    "q3 = (\n",
    "    payments_monthly.alias(\"p\")\n",
    "    .join(rides_monthly.alias(\"r\"), [\"rider_id\", \"year\", \"month\"], \"left\")\n",
    "    .fillna({\"rides_per_month\": 0, \"minutes_per_month\": 0})\n",
    "    .select(\"rider_id\", \"year\", \"month\", \"spend_per_month\", \"rides_per_month\", \"minutes_per_month\")\n",
    "    .orderBy(\"year\", \"month\", \"rider_id\")\n",
    ")\n",
    "\n",
    "display(q3)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Project BikeShare",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
